---
title: Hash Join
---

# Место среди алгоритмов соединения

Реляционные СУБД используют три базовых метода соединения:

| Алгоритм         | Механизм                      | Когда хорош                                           |
| ---------------- | ----------------------------- | ----------------------------------------------------- |
| Nested Loop Join | Перебор + индекс              | Малые входы / точечные выборки                        |
| Merge Join       | Сортировка и слияние          | Данные уже отсортированы / крупные таблицы            |
| **Hash Join**    | Хеширование + поиск в бакетах | Большие объёмы, равенства ключей, ограниченная память |

Hash Join появился как решение, не требующее ни сортировки,
ни индексов, и обеспечивающее линейное поведение на больших таблицах.

---

# Идея

> «Разбить строки по ключу на небольшие группы (бакеты) и сравнивать только внутри своей группы».

Это резко снижает число сравнений:
если хеш-функция равномерна, то вместо сравнения миллиона строк со всеми миллионом,
каждая строка проверяет только свой небольшой бакет.

---

# Базовый Hash Join (когда «build» умещается в память)

## Этап 1 — Build

Обычно строится по меньшей таблице — пусть это таблица **R**.

Пусть `R` содержит 12 000 строк, ключ — `customer_id`.

### Пример

Пусть хеш-функция распределяет строки `R` в 4 бакета:

```
bucket 0: 3100 строк
bucket 1: 2950 строк
bucket 2: 3005 строк
bucket 3: 2945 строк
```

Хеш-таблица (`H`) будет представлять собой массив этих бакетов в памяти.

Условные страницы, которые были прочитаны буферным менеджером:

```
R_page_1  → bucket 0
R_page_2  → bucket 3
R_page_3  → bucket 1
...
R_page_n  → bucket i
```

Каждая строка добавляется в соответствующий список внутри бакета.

---

## Этап 2 — Probe

Теперь читаем большую таблицу `S` (например, 3 млн строк).

Для каждой строки:

```
h = hash(s.customer_id)
bucket = H[h]
сравнить со всеми строками из bucket
```

Важно: **сравнение идёт только с теми строками, у кого хеш совпал**.
Это не только экономия времени, но и сохранение локальности — бакеты находятся в памяти.

---

# Подробный пример соединения

Пусть мы соединяем таблицы **Orders (S)** и **Customers (R)**:

```
SELECT *
FROM Customers R
JOIN Orders S ON R.id = S.customer_id;
```

И пусть после построения хеша по R получили:

```
bucket 0: ids {1, 5, 9}
bucket 1: ids {2, 6}
bucket 2: ids {3, 7, 11}
bucket 3: ids {4, 8, 10}
```

Рассмотрим строку из S:

```
order_id = 501
customer_id = 7
```

Хеш-функция (`h1`):

```
h1(7) = 2
```

Значит:

```
смотрим только bucket 2
```

Сравнения:

```
7 == 3 ? нет
7 == 7 ? да  → соединяем
7 == 11? нет
```

Строка S проверила **только 3 строки вместо тысяч**.

---

# Что происходит в памяти: пример с доступом к страницам

Допустим, таблица R занимает 120 страниц, таблица S — 1800 страниц.
Буферный пул — 512 страниц.

### Build-fаза:

1. Читаем страницы R (120 подряд → прекрасно ложится в пул).
2. Каждая строка помещается в один из бакетов.
3. Итог:

   * 120 чтений (последовательных)
   * хеш-таблица целиком в памяти
   * пул почти не испытывает давления

---

### Probe-фаза:

Теперь начинается потоковое чтение S:

1. Постранично загружается каждая страница Orders:

   ```
   S_page_1 → пробегаем строки → обращаемся к бакетам
   S_page_2 → пробегаем строки → обращаемся к бакетам
   ...
   S_page_1800
   ```

2. Бакеты не перегружают пул: они уже находятся в памяти, почти не вытесняются.

3. Если совпадений мало и ключи равномерно распределены, буферный менеджер почти не страдает от случайных скачков.

**Итог:**

* ~1800 чтений для S
* почти нулевые повторные чтения
* стабильная линейная производительность

---

# Когда «build» не помещается в память

(внешний Hash Join / Grace Hash Join)

Пусть build-сторона R слишком большая:
120 000 строк, 4000 страниц → не помещаются в 512 страниц памяти.

Тогда включается **разбиение на партиции**.

---

## Проход 1 — Partition

Хеш-функция `h1` делит обе таблицы на k бакетов:

```
R → R0, R1, R2, ... R7
S → S0, S1, S2, ... S7
```

То есть создаются временные файлы:

```
R0.tmp, R1.tmp, ..., R7.tmp
S0.tmp, S1.tmp, ..., S7.tmp
```

Каждая пара Ri и Si гарантированно содержит *все строки с одинаковыми ключами*.

Пример:

```
R0: 500 страниц
R1: 510 страниц
R2: 495 страниц
...
R7: 505 страниц
```

Каждый бакет теперь помещается в память.

---

## Проход 2 — Build + Probe по каждому бакету

Например, бакет `R3` (480 страниц):

1. читаем R3 в память → строим хеш по R3;
2. читаем S3 → пробегаем строки → сравниваем с бакетом из R3.

Повторяется для всех бакетов 0..7.

Преимущество:
**алгоритм остаётся линейным**, даже если таблицы в десятки раз больше памяти.

---

# Пример со скью (перекосом данных)

Пусть хеш-функция распределила ключи:

```
bucket 0: 10% строк
bucket 1: 12%
bucket 2: 11%
bucket 3: 55%  ← очень плохо
bucket 4: 12%
```

Бакет №3 слишком велик и не помещается в память.

PostgreSQL делает два шага:

1. разбивает бакет №3 вторичной хеш-функцией (`h2`),
2. обрабатывает его в несколько проходов.

Если это тоже не помогает (пример: один клиент имеет 1 млн заказов),
включается **специальный алгоритм для “тяжёлых” ключей**, где такой ключ обрабатывается отдельно.

---

# Формулы с реальными числами

Пусть:

* `R`: 10000 строк (40 страниц)
* `S`: 600000 строк (2400 страниц)

### NLJ без индекса:

```
40 + 10000 * 2400 ≈ 24 000 040 I/O
```

### Hash Join в памяти:

```
build: 40
probe: 2400
итого: 2440 I/O
```

Разница — *четыре порядка*.

---

# Когда Hash Join — не лучший вариант

| Ситуация                        | Почему                                       |
| ------------------------------- | -------------------------------------------- |
| Соединение не по равенству      | Хеш-группировки не работают                  |
| Требуется отсортированный вывод | После JOIN всё равно сортировать             |
| Очень мало памяти               | Будет много проходов разбиения               |
| Сильный скью                    | Некоторые бакеты становятся слишком большими |

---

# Оптимизатор PostgreSQL выбирает Hash Join, когда…

✓ обе таблицы крупные
✓ нет подходящих индексов
✓ соединение по равенству
✓ памяти достаточно для хотя бы одного бакета
✓ стоимость сортировки для merge join выше

---

# Итог

* Hash Join — алгоритм линейного масштаба: каждая строка обрабатывается ровно один раз.
* Он особенно эффективен на больших таблицах и соединениях по равенству.
* При нехватке памяти автоматически включается внешнее разбиение.
* Оптимизатор выбирает его, когда нужно соединять большие объёмы данных быстро и предсказуемо.

> «Если соединение по равенству и таблицы большие — Hash Join почти всегда оптимален».

---
# Связанные темы

- [Nested Join](./Nested_Join.md)
- [Merge Join](./Merge_Join.md)
- [Буферный менеджер](/Nodes/DataManagement_and_Storage/DBMS/Fundamental/Components/Buffer_Manager/Buffer_Manager.md)