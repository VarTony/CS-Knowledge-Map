---
title: Двухпроходный алгоритм
---

# Двухпроходный алгоритм

К началу 80-х годов стало очевидно: однопроходного алгоритма недостаточно. Объём данных рос, и отношение уже не помещалось целиком в оперативную память. Но при этом доступ к диску по-прежнему оставался самым дорогим ресурсом. Требовалось сохранить ключевой принцип — **минимум обращений к диску**, — но при недостатке памяти выполнить задачу всё равно за фиксированное число проходов.

Так возник двухпроходный (two-pass) алгоритм — фундамент внешней обработки данных. Он лежит в основе внешнего хеш-соединения, сортировки и операторов `GROUP BY`, `DISTINCT`.  
**Идея:** разбить отношение на части, каждая из которых помещается в память, а затем обработать эти части отдельно, не возвращаясь к исходным данным.

---

## Архитектура памяти и временного хранения

| Компонент                     | Роль                                                                          |
|-------------------------------|---------------------------------------------------------------------------    |
| **Входной буфер**             | Потоковое чтение страниц исходных данных                                      |
| **Промежуточный буфер**       | Построение структуры для одной партии (хэш-таблица, агрегаты)                 |
| **Выходной буфер**            | Формирование результирующих страниц                                           |
| **Файлы партий (разбиений)**  | Временные сегменты на диске; каждая партия гарантированно помещается в память |

СУБД не пытается работать с таблицей целиком. Вместо этого она **создаёт партии** — независимые куски данных, которые можно полностью обработать в оперативной памяти.

---

# Как работает двухпроходный алгоритм

## Шаг 1. Разбиение данных (partitioning pass)

СУБД читает таблицы **по одному разу** и распределяет строки по временным файлам (партиям) с помощью детерминированной функции (обычно хеш-функции).  
**Главное правило:**  
*все строки, которые должны быть сопоставлены или объединены, обязательно попадают в одну и ту же партию.*

```

Исходная таблица S → S₁, S₂, ... Sₖ
Исходная таблица R → R₁, R₂, ... Rₖ

````

Каждая партия устроена так, что **Sᵢ и Rᵢ теперь достаточно малы**, чтобы поместиться в память.

---

## Шаг 2. Обработка партий (processing pass)

Таблица больше не читается целиком. Вместо этого СУБД поочерёдно загружает каждую пару партий `Sᵢ` и `Rᵢ`:

1. `Sᵢ` загружается полностью в память и строит структуру (хэш-таблица).
2. `Rᵢ` читается потоково, каждая строка сравнивается с данными в памяти.(Стоит отметить, что здесь тот же принцип, что и в однопроходном варианте)
3. Результат немедленно отправляется в выходной буфер.
4. После завершения партии память очищается, загружается следующая.

Таким образом, **все данные обрабатываются за два прохода** — один для разбиения, один для соединения.

---

## Двухпроходный алгоритм (Volcano Model)

### **Фаза 1 — open()**

* Создаётся план разбиения: выбирается количество партий и хеш-функция.
* Идёт однократное чтение исходных таблиц, кортежи распределяются по временным файлам.

```text
open():
    plan_partitioning(k)
    for each page in S:
        write S_{h1(s.key)} ← s
    for each page in R:
        write R_{h1(r.key)} ← r
    current_partition ← 1
````

---

### **Фаза 2 — get-next()**

Это основная рабочая часть:

```text
get-next():
    while current_partition ≤ k:
        if not loaded(Sᵢ):
            load Sᵢ into memory
            build hash_table(Sᵢ)
            open stream Rᵢ
        while Rᵢ has tuple r:
            if match in hash_table:
                return join(r, match)
        current_partition++
    return EOF
```

*Для OUTER JOIN(LEFT/RIGHT/FULL) на этой фазе после исчерпания `Rᵢ` эмитируются строки из `Sᵢ`, не имевшие совпадений: `Sᵢ ⨝ NULL`.*

---

### **Фаза 3 — close()**

```text
close():
    drop_partition_files()
    free_memory_structures()
```

---

## Резюме фаз и буферов

| Фаза         | Действие            | Буферы задействованы                                             |
| ------------ | ------------------- | ---------------------------------------------------------------- |
| **open**     | Разбиение на партии | входной буфер, выходной буфер (для временных файлов)             |
| **get-next** | Обработка партий    | промежуточный (хэш в памяти), входной буфер (партия R), выходной |
| **close**    | Очистка             | все буферы освобождаются                                         |

---

# Универсальная схема применения

| Операция       | Двухпроходная реализация (в памяти на партию) |
| -------------- | --------------------------------------------- |
| **JOIN**       | Хеш-соединение по партиям                     |
| **GROUP BY**   | Агрегация по партиям                          |
| **DISTINCT**   | Удаление дубликатов по партиям                |
| **SORT-MERGE** | Сортировка небольших run'ов и их слияние      |

> **Все операции работают по одной идее:**
> *разбить данные на независимые партии, обработать каждую партию в памяти, не возвращаясь к исходному отношению.*

---

# Альтернатива: Двухпроходная сортировка (External Merge Sort)

* Шаг 1: таблица делится на run’ы, каждый сортируется в памяти и записывается на диск.
* Шаг 2: все run’ы сливаются (merge) в один отсортированный поток.

На основе этой сортировки работают:

* **Sort-Merge Join**
* **GROUP BY после сортировки**
* **DISTINCT после сортировки**

Идея та же: *два прохода, память используется только для работы с одной партией*.

---

# Итог

Двухпроходный алгоритм — это естественное расширение однопроходного алгоритма на случай, когда данные превышают объём оперативной памяти.

> **Память удерживает партию.
> Диск хранит остальное.
> Два прохода — и задача решена.**

---

## Связанные темы

- [Однопроходный алгоритм](./One_Pass_Algorithm.md)
- [Буферный менеджер и page replacement](/Nodes/DataManagement_and_Storage/DBMS/Fundamental/Components/Buffer_Manager.md)
- [Hash Join](./Nodes/DataManagement_and_Storage/DBMS/Fundamental/Components/Query_Optimizer/JOINs/Hash_Join.md)
- [Sort-Merge Join](./Nodes/DataManagement_and_Storage/DBMS/Fundamental/Components/Query_Optimizer/JOINs/Merge_Join.md)

